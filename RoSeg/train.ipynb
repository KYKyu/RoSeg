{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94c83f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import transforms\n",
    "from sklearn.metrics import f1_score, jaccard_score, precision_score, recall_score, accuracy_score\n",
    "\n",
    "from albumentations import Compose, HorizontalFlip, VerticalFlip, ColorJitter, Affine\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "from ModelArchitecture.RoSeg import RoSeg\n",
    "from ModelArchitecture.DiceLoss import dice_loss\n",
    "from ImageLoader2D import load_data\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d00e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, images, masks, transform=None):\n",
    "        self.images = images\n",
    "        self.masks = masks\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        mask = self.masks[idx]\n",
    "\n",
    "        image_np = image.permute(1, 2, 0).cpu().numpy()\n",
    "        mask_np = mask.permute(1, 2, 0).cpu().numpy()\n",
    "        mask_np = np.squeeze(mask_np)\n",
    "\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image_np, mask=mask_np)\n",
    "            image = augmented['image']\n",
    "            mask = augmented['mask']\n",
    "\n",
    "        return image, mask\n",
    "    \n",
    "def polynomial_decay_lambda(epoch):\n",
    "    if epoch >= decay_steps:\n",
    "        return end_learning_rate / starter_learning_rate\n",
    "    else:\n",
    "        return ((starter_learning_rate - end_learning_rate) * \\\n",
    "               (1 - epoch / decay_steps)**decay_power + end_learning_rate) / starter_learning_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deda20f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = Compose([\n",
    "    HorizontalFlip(p=0.5),\n",
    "    VerticalFlip(p=0.5),\n",
    "    ColorJitter(brightness=0.6, contrast=0.2, saturation=0.1, hue=0.01, always_apply=True),\n",
    "    Affine(scale=(0.5, 1.5), translate_percent=(-0.125, 0.125), rotate=(-180, 180), shear=(-22.5, 22), always_apply=True),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "val_transform = Compose([ToTensorV2()])\n",
    "    \n",
    "img_size = 352\n",
    "dataset_type = 'cvc-clinicdb' # Options: kvasir/cvc-clinicdb/cvc-colondb/etis-laribpolypdb\n",
    "starter_learning_rate = 1e-4\n",
    "end_learning_rate = 1e-6\n",
    "decay_steps = 1000\n",
    "decay_power = 0.2\n",
    "\n",
    "batch_size = 8\n",
    "epochs = 300\n",
    "seed_value = 58800\n",
    "starting_filters = 17\n",
    "min_loss_for_saving = 0.1\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "torch.manual_seed(seed_value)\n",
    "np.random.seed(seed_value)\n",
    "random.seed(seed_value)\n",
    "\n",
    "g = torch.Generator()\n",
    "g.manual_seed(seed_value)\n",
    "\n",
    "ct = datetime.now().strftime('%Y%m%d-%H%M%S')\n",
    "model_type = \"RoSeg\"\n",
    "\n",
    "base_dir = os.getcwd()\n",
    "model_path = os.path.join(base_dir, f'ModelSave/{dataset_type}/{model_type}_{ct}_v2.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e321dd76",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(os.path.join(base_dir, f'ModelSave/{dataset_type}'), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2b09bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data, y_data = load_data(img_size, img_size, -1, 'cvc-clinicdb', \"../datasets/CVC-ClinicDB/CVC-ClinicDB/\")\n",
    "\n",
    "total_size = len(x_data)\n",
    "train_size = int(0.8 * total_size)\n",
    "val_size = int(0.1 * total_size)\n",
    "test_size = total_size - train_size - val_size\n",
    "\n",
    "indices = torch.randperm(total_size)\n",
    "\n",
    "x_data = x_data[indices]\n",
    "y_data = y_data[indices]\n",
    "\n",
    "x_train, y_train = x_data[:train_size], y_data[:train_size]\n",
    "x_val, y_val = x_data[train_size:train_size + val_size], y_data[train_size:train_size + val_size]\n",
    "x_test, y_test = x_data[train_size + val_size:], y_data[train_size + val_size:]\n",
    "\n",
    "train_dataset = CustomDataset(x_train, y_train, transform=train_transform)\n",
    "val_dataset = CustomDataset(x_val, y_val, transform=val_transform)\n",
    "test_dataset = CustomDataset(x_test, y_test, transform=val_transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True, generator=g)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "log_path = os.path.join(base_dir, f\"ProgressFull/{dataset_type}_training_log_{model_type}_{ct}_v2.csv\")\n",
    "log_df = pd.DataFrame(columns=[\"epoch\", \"train_loss\", \"val_loss\", \"lr\"])\n",
    "log_df.to_csv(log_path, index=False)\n",
    "\n",
    "model = RoSeg(input_channels=3, out_classes=1, starting_filters=starting_filters).to(device)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=starter_learning_rate, weight_decay=starter_learning_rate)\n",
    "lr_scheduler = optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=polynomial_decay_lambda)\n",
    "\n",
    "loss_fn = dice_loss\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_train_loss = 0\n",
    "    num_train_batches = 0\n",
    "    \n",
    "    for x_batch, y_batch in train_loader:\n",
    "        x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(x_batch)\n",
    "        loss = loss_fn(outputs, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_train_loss += loss.item()\n",
    "        num_train_batches += 1\n",
    "        \n",
    "    avg_train_loss = total_train_loss / num_train_batches\n",
    "\n",
    "    lr_scheduler.step()\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    num_val_batches = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for x_val, y_val in val_loader:\n",
    "            x_val, y_val = x_val.to(device), y_val.to(device)\n",
    "            outputs = model(x_val)\n",
    "            loss = loss_fn(outputs, y_val)\n",
    "            val_loss += loss.item()\n",
    "            num_val_batches += 1\n",
    "            \n",
    "    avg_val_loss = val_loss / num_val_batches\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}, LR: {current_lr:.6f}\")\n",
    "\n",
    "    new_row = {\"epoch\": epoch+1, \"train_loss\": avg_train_loss, \"val_loss\": avg_val_loss, \"lr\": current_lr}\n",
    "    pd.DataFrame([new_row]).to_csv(log_path, mode='a', header=False, index=False)\n",
    "    \n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "        print(f\"Model saved with val_loss {avg_val_loss:.4f}\")\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060932e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, dataloader):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for x_batch, y_batch in dataloader:\n",
    "            x_batch = x_batch.to(device)\n",
    "            outputs = model(x_batch).cpu() > 0.5\n",
    "            all_preds.append(outputs)\n",
    "            all_labels.append(y_batch)\n",
    "\n",
    "    preds = torch.cat(all_preds).numpy().astype(bool)\n",
    "    labels = torch.cat(all_labels).numpy().astype(bool)\n",
    "    \n",
    "    return {\n",
    "        'dice': f1_score(labels.flatten(), preds.flatten()),\n",
    "        'iou': jaccard_score(labels.flatten(), preds.flatten()),\n",
    "        'precision': precision_score(labels.flatten(), preds.flatten()),\n",
    "        'recall': recall_score(labels.flatten(), preds.flatten()),\n",
    "        'accuracy': accuracy_score(labels.flatten(), preds.flatten())\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0519ebe4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(model_path))\n",
    "metrics = evaluate(model, test_loader)\n",
    "\n",
    "print(\"Test Metrics:\")\n",
    "for k, v in metrics.items():\n",
    "    print(f\"{k}: {v:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b8b618",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RoSeg (python 3.10)",
   "language": "python",
   "name": "dformer"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
